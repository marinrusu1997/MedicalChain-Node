"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const demux_1 = require("demux");
const errors_1 = require("./errors");
const MigrationRunner_1 = require("./MigrationRunner");
/**
 * Connects to a Postgres database using [MassiveJS](https://github.com/dmfay/massive-js). Make sure to call
 * `setupDatabase` to create the needed internally-used tables `_migration`, `_index_state`, and `_block_number_txid`.
 * This will also automatically migrate the database with the provided MigrationSequence if named `init`.
 *
 * @param handlerVersions     See `HandlerVersion` parameter from demux-js
 *
 * @param massiveInstance     An instance of of a `massive` object provided by MassiveJS, connected to the database
 *                            you want this instance to interface with
 *
 * @param dbSchema            The name of the schema you would like to use. If it doesn't exist, it will be created when
 *                            `setupDatabase` is called.
 *
 * @param migrationSequences  An array of `MigrationSequence`s available to call via
 *                            `state.migrate(<name of sequence>)`, commonly from `Updater`'s `apply` functions that also
 *                            change the `HandlerVersion`.
 */
class MassiveActionHandler extends demux_1.AbstractActionHandler {
    constructor(handlerVersions, massiveInstance, dbSchema = 'public', migrationSequences = []) {
        super(handlerVersions);
        this.handlerVersions = handlerVersions;
        this.massiveInstance = massiveInstance;
        this.dbSchema = dbSchema;
        this.migrationSequences = migrationSequences;
        this.allMigrations = [];
        this.migrationSequenceByName = {};
        for (const migrationSequence of migrationSequences) {
            if (this.migrationSequenceByName.hasOwnProperty(migrationSequence.sequenceName)) {
                throw new errors_1.NonUniqueMigrationSequenceError();
            }
            this.migrationSequenceByName[migrationSequence.sequenceName] = migrationSequence;
            for (const migration of migrationSequence.migrations) {
                this.allMigrations.push(migration);
            }
        }
    }
    /**
     * Migrates the database by the given sequenceName. There must be a `MigrationSequence` with this name, or this will
     * throw an error.
     *
     * @param sequenceName  The name of the MigrationSequence to be run.
     */
    migrate(sequenceName, pgp = this.massiveInstance.instance, initial = false) {
        return __awaiter(this, void 0, void 0, function* () {
            const migrationSequence = this.migrationSequenceByName[sequenceName];
            if (!migrationSequence) {
                throw new errors_1.NonExistentMigrationError(sequenceName);
            }
            let ranMigrations = [];
            if (!initial) {
                ranMigrations = yield this.loadRanMigrations();
            }
            const extendedMigrations = ranMigrations.concat(migrationSequence.migrations);
            const migrationRunner = new MigrationRunner_1.MigrationRunner(this.massiveInstance.instance, extendedMigrations, this.dbSchema, true);
            yield migrationRunner.migrate(migrationSequence.sequenceName, this.lastProcessedBlockNumber + 1, pgp, initial);
            yield this.massiveInstance.reload();
        });
    }
    /**
     * Sets up the database by idempotently creating the schema, installing CyanAudit, creates internally used tables, and
     * runs any initial migration sequences provided.
     */
    setup(initSequenceName = 'init') {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.initialized) {
                return;
            }
            if (!this.migrationSequenceByName[initSequenceName]) {
                if (initSequenceName === 'init') {
                    console.warn(`No 'init' Migration sequence was provided, nor was a different initSequenceName.` +
                        'No initial migrations have been run.');
                }
                else {
                    throw new errors_1.NonExistentMigrationError(initSequenceName);
                }
            }
            try {
                //const migrationRunner = new MigrationRunner_1.MigrationRunner(this.massiveInstance.instance, [], this.dbSchema);
               // yield migrationRunner.setup();
               // yield this.massiveInstance.reload();
              //  yield this.migrate(initSequenceName, this.massiveInstance.instance, true);
            }
            catch (err) {
                throw new demux_1.NotInitializedError('Failed to migrate the postgres database.', err);
            }
        });
    }
    get schemaInstance() {
        if (this.dbSchema === 'public') {
            return this.massiveInstance;
        }
        else {
            return this.massiveInstance[this.dbSchema];
        }
    }
    handleWithState(handle) {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.massiveInstance.withTransaction((tx) => __awaiter(this, void 0, void 0, function* () {
                let db;
                if (this.dbSchema === 'public') {
                    db = tx;
                }
                else {
                    db = tx[this.dbSchema];
                }
                this.warnOverwrite(db, 'migrate');
                db.migrate = (sequenceName) => __awaiter(this, void 0, void 0, function* () { return yield this.migrate(sequenceName, tx.instance); });
                this.warnOverwrite(db, 'txid');
                db.txid = (yield tx.instance.one('select txid_current()')).txid_current;
                try {
                    yield handle(db);
                }
                catch (err) {
                    throw err; // Throw error to trigger ROLLBACK
                }
            }), {
                mode: new this.massiveInstance.pgp.txMode.TransactionMode({
                    tiLevel: this.massiveInstance.pgp.txMode.isolationLevel.serializable,
                }),
            });
        });
    }
    updateIndexState(state, block, isReplay, handlerVersionName) {
        return __awaiter(this, void 0, void 0, function* () {
            const { blockInfo } = block;
            const fromDb = (yield state._index_state.findOne({ id: 1 })) || {};
            const toSave = Object.assign({}, fromDb, { block_number: blockInfo.blockNumber, block_hash: blockInfo.blockHash, is_replay: isReplay, handler_version_name: handlerVersionName });
            yield state._index_state.save(toSave);
            yield state._block_number_txid.insert({
                block_number: blockInfo.blockNumber,
                txid: state.txid,
            });
        });
    }
    loadIndexState() {
        return __awaiter(this, void 0, void 0, function* () {
            const defaultIndexState = {
                block_number: 0,
                block_hash: '',
                handler_version_name: 'v1',
                is_replay: false,
            };
            const indexState = (yield this.schemaInstance._index_state.findOne({ id: 1 })) || defaultIndexState;
            return {
                blockNumber: indexState.block_number,
                blockHash: indexState.block_hash,
                handlerVersionName: indexState.handler_version_name,
                isReplay: indexState.is_replay,
            };
        });
    }
    loadRanMigrations() {
        return __awaiter(this, void 0, void 0, function* () {
            const processedMigrationRows = yield this.massiveInstance._migration.find();
            const processedMigrations = processedMigrationRows.map((row) => {
                return {
                    name: row.name,
                    sequenceName: row.sequence,
                    blockNumber: row.block_number,
                };
            });
            const ranMigrations = [];
            for (const [index, processedMigration] of processedMigrations.entries()) {
                const expectedName = this.allMigrations[index].name;
                const actualName = processedMigration.name;
                if (expectedName !== actualName) {
                    throw new errors_1.MismatchedMigrationsError(expectedName, actualName, index);
                }
                ranMigrations.push(this.allMigrations[index]);
            }
            return ranMigrations;
        });
    }
    rollbackTo(blockNumber) {
        return __awaiter(this, void 0, void 0, function* () {
            const blockNumberTxIds = yield this.schemaInstance._block_number_txid.where('block_number > $1', [blockNumber], {
                order: [{
                        field: 'block_number',
                        direction: 'desc',
                    }],
            });
            for (const { block_number: rollbackNumber, txid } of blockNumberTxIds) {
                this.log.info(`ROLLING BACK BLOCK ${rollbackNumber}`);
                yield this.massiveInstance.cyanaudit.fn_undo_transaction(txid);
            }
            this.log.info(`Rollback complete!`);
        });
    }
    warnOverwrite(db, toOverwrite) {
        if (db.hasOwnProperty(toOverwrite)) {
            console.warn(`Assignment of '${toOverwrite}' on Massive object instance is overwriting property of the same ` +
                'name. Please use a different table or schema name.');
        }
    }
}
exports.MassiveActionHandler = MassiveActionHandler;
